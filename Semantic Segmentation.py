# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m0e3DyjQ5uF90hJIURSzWRUv0OMqSlvJ
"""



import os
import glob
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
import albumentations as A
import torch
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import os
import glob
import numpy as np
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torchvision.datasets import ImageFolder
from torchvision.transforms import Compose, Resize, RandomHorizontalFlip, ToTensor
import albumentations as A
from albumentations.pytorch import ToTensorV2



class_mapping = {
    "Animal": 0,
    "Archway": 1,
    "Bicyclist": 2,
    "Bridge": 3,
    "Building": 4,
    "Car": 5,
    "CartLuggagePram": 6,
    "Child": 7,
    "Column_Pole": 8,
    "Fence": 9,
    "LaneMkgsDriv": 10,
    "LaneMkgsNonDriv": 11,
    "Misc_Text": 12,
    "MotorcycleScooter": 13,
    "OtherMoving": 14,
    "ParkingBlock": 15,
    "Pedestrian": 16,
    "Road": 17,
    "RoadShoulder": 18,
    "Sidewalk": 19,
    "SignSymbol": 20,
    "Sky": 21,
    "SUVPickupTruck": 22,
    "TrafficCone": 23,
    "TrafficLight": 24,
    "Train": 25,
    "Tree": 26,
    "Truck_Bus": 27,
    "Tunnel": 28,
    "VegetationMisc": 29,
    "Void": 30,
    "Wall": 31
}


def get_label_mapping(file_path):
    label_mapping = {}
    with open(file_path, 'r') as f:
        for line in f:
            if not line.startswith("#"):  # Ignore comments
                cols = line.split(":")
                rgb = tuple(map(int, cols[0].strip().replace('"','').split()))
                label = cols[1].strip().replace('"', '').replace(',', '')  # Remove quotes and commas
                label_mapping[rgb] = label
    return label_mapping

label_mapping = get_label_mapping('/content/drive/MyDrive/ai data/label_colors.txt')

def apply_label_mapping(label_image, label_mapping, class_mapping):
    label_image_rgb = cv2.cvtColor(label_image, cv2.COLOR_BGR2RGB)
    label_mapped = np.zeros((label_image.shape[0], label_image.shape[1]), dtype=np.uint8)
    
    for rgb, class_name in label_mapping.items():
        label_mapped[np.where((label_image_rgb == rgb).all(axis=-1))] = class_mapping[class_name]

    return label_mapped



def load_dataset(data_path, label_mapping, class_mapping):
    all_files = sorted(glob.glob(os.path.join(data_path, "*.png")))
    
    # Divide them into images and label images based on file name
    image_files = [f for f in all_files if "_L" not in f]
    label_files = [f for f in all_files if "_L" in f]
    
    # Apply label mapping to labels
    labels = [apply_label_mapping(cv2.imread(x), label_mapping, class_mapping) for x in label_files]
    
    return image_files, labels


train_images, train_labels = load_dataset('/content/drive/MyDrive/ai data/train', label_mapping, class_mapping)
test_images, test_labels = load_dataset('/content/drive/MyDrive/ai data/test', label_mapping, class_mapping)
print("Number of training samples:", len(train_images))
print("Number of testing samples:", len(test_images))

def visualize_samples(images, labels):
    num_samples = len(images)
    num_rows = int(np.ceil(np.sqrt(num_samples)))
    num_cols = int(np.ceil(num_samples / num_rows))
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 12))

    for i, ax in enumerate(axes.flat):
        ax.imshow(cv2.cvtColor(cv2.imread(images[i]), cv2.COLOR_BGR2RGB))
        ax.set_title(labels[i])
        ax.axis('off')

    plt.tight_layout()
    plt.show()

# Visualize training samples
visualize_samples(train_images[:9], train_labels[:9])

# Visualize testing samples
visualize_samples(test_images[:9], test_labels[:9])

# Define your transformations


transform = A.Compose([
    A.Resize(224, 224),
    A.HorizontalFlip(),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])



# Define your augmented dataset path
augmented_train_data_path = os.path.join(os.path.dirname('/content/drive/MyDrive/ai data/train'), 'augmented_images')
os.makedirs(augmented_train_data_path, exist_ok=True)


# Apply the transformations and save the augmented images
for i, (img_file, label) in enumerate(zip(train_images, train_labels)):
    img = cv2.imread(img_file)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    mask = label
    for j in range(2):  
      augmented = transform(image=img, mask=mask)
      img_augmented = augmented['image']
      label_augmented = augmented['mask']

      # Convert the tensors back to numpy arrays
      img_augmented_np = img_augmented.permute(1, 2, 0).numpy()
      label_augmented_np = label_augmented.numpy()

        # Convert the images back to the range [0, 255]
      img_augmented_np = (img_augmented_np * 255).astype(np.uint8)
      

      cv2.imwrite(os.path.join(augmented_train_data_path, f"{i}_augmented_{j}.png"), cv2.cvtColor(img_augmented_np, cv2.COLOR_RGB2BGR))  # Save the augmented image
      np.save(os.path.join(augmented_train_data_path, f"{i}_augmented_{j}.npy"), label_augmented_np)  # Save the augmented mask


class SemanticSegmentationDataset(Dataset):

    def __init__(self, img_dir, label_dir, transform=None):
        self.img_dir = img_dir
        self.label_dir = label_dir
        self.img_files = sorted(glob.glob(os.path.join(self.img_dir, "*.png")))
        self.label_files = sorted(glob.glob(os.path.join(self.label_dir, "*.npy")))
        self.transform = transform

    def __len__(self):
        return len(self.img_files)
    def __getitem__(self, idx):
      img_path = self.img_files[idx]
      label_path = self.label_files[idx]

      img = cv2.imread(img_path)
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      label = np.load(label_path)

      if self.transform is not None:
        augmented = self.transform(image=img, mask=label)
        img = augmented['image']
        label = augmented['mask']
        
        # Save the augmented mask
        np.save(os.path.join(augmented_train_data_path, f"{idx}_augmented.npy"), label)

    # Convert to Float tensors before returning
      img = img.float()

    # Check that all labels are within the expected range
      max_label = label.max()
      if max_label >= len(class_mapping):
        print(f"Max label in file {label_path} is {max_label}, which is out of range.")
        print(f"Unique labels in this file: {np.unique(label)}")
      assert max_label < len(class_mapping), "Label out of range"

      label = label.long()  # Convert labels to LongTensor

      return img, label





# Get the list of augmented image files and corresponding label files
augmented_image_files = sorted(glob.glob(os.path.join(augmented_train_data_path, "*.png")))
augmented_label_files = sorted(glob.glob(os.path.join(augmented_train_data_path, "*.npy")))

# Load the augmented dataset
transform = A.Compose([
    ToTensorV2()
])

augmented_dataset = SemanticSegmentationDataset(augmented_train_data_path, augmented_train_data_path, transform=transform)

print("Total number of samples after augmentation:", len(augmented_dataset))

# Split into training and validation sets
train_size = int(0.9 * len(augmented_dataset))  # 90% for training
val_size = len(augmented_dataset) - train_size  # 10% for validation
train_dataset, val_dataset = torch.utils.data.random_split(augmented_dataset, [train_size, val_size])

# Create dataloaders
batch_size = 8
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)


#pre-trained Deep-labV3(resnet101)
import torch
from torchvision import models
from time import time
import matplotlib.pyplot as plt

def get_model(num_classes):
    model = models.segmentation.deeplabv3_resnet101(pretrained=True, progress=True)
    model.classifier[4] = torch.nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))
    return model

def metrics_per_batch(output, target, num_classes):
    pred = output.argmax(dim=1).view(-1)
    target = target.view(-1)

    conf_matrix = torch.zeros(num_classes, num_classes)
    for t, p in zip(target, pred):
        conf_matrix[t.long(), p.long()] += 1

    iou_list = []
    for i in range(num_classes):
        true_class = conf_matrix[i, i]
        false_pos = conf_matrix[:, i].sum() - true_class
        false_neg = conf_matrix[i, :].sum() - true_class
        true_pos = true_class
        iou = true_pos / (true_pos + false_pos + false_neg + 1e-6)
        iou_list.append(iou)

    mean_iou = sum(iou_list) / num_classes

    total_correct = conf_matrix.trace()
    total_pixels = conf_matrix.sum()
    accuracy = total_correct / total_pixels

    return mean_iou, accuracy

num_classes = len(class_mapping)
model = get_model(num_classes)

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""
    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):
        
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        self.path = path
        self.trace_func = trace_func
    def __call__(self, val_loss, model):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0


    def save_checkpoint(self, val_loss, model):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

early_stopping = EarlyStopping(patience=7, path='checkpoint.pt')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

num_epochs = 10
train_loss_values = []
val_loss_values = []
train_iou_values = []
val_iou_values = []
train_acc_values = []
val_acc_values = []

start_time = time()
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    train_iou = 0.0
    train_acc = 0.0

    for images, labels in train_dataloader:
        images = images.to(device)
        labels = labels.long().to(device)

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs['out'], labels)

        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        iou, acc = metrics_per_batch(outputs['out'], labels, num_classes)
        train_iou += iou
        train_acc += acc

    train_loss /= len(train_dataloader)
    train_iou /= len(train_dataloader)
    train_acc /= len(train_dataloader)

    model.eval()
    val_loss = 0.0
    val_iou = 0.0
    val_acc = 0.0

    for images, labels in val_dataloader:
        images = images.to(device)
        labels = labels.long().to(device)

        with torch.no_grad():
            outputs = model(images)
            loss = criterion(outputs['out'], labels)

        val_loss += loss.item()
        iou, acc = metrics_per_batch(outputs['out'], labels, num_classes)
        val_iou += iou
        val_acc += acc

    val_loss /= len(val_dataloader)
    val_iou /= len(val_dataloader)
    val_acc /= len(val_dataloader)

    train_loss_values.append(train_loss)
    val_loss_values.append(val_loss)
    train_iou_values.append(train_iou)
    val_iou_values.append(val_iou)
    train_acc_values.append(train_acc)
    val_acc_values.append(val_acc)

    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Train IoU: {train_iou}, Val IoU: {val_iou}, Train Acc: {train_acc}, Val Acc: {val_acc}')

    scheduler.step()

    early_stopping(val_loss, model)
    if early_stopping.early_stop:
        print("Early stopping")
        break

end_time = time()

print(f"Training time: {end_time - start_time}")

model.load_state_dict(torch.load('checkpoint.pt'))

# Evaluation on the test dataset is similar to the evaluation on the validation dataset

plt.figure(figsize=(10, 5))
plt.title("Loss Graph")
plt.plot(range(1, num_epochs+1), train_loss_values, label='Train')
plt.plot(range(1, num_epochs+1), val_loss_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("IoU Graph")
plt.plot(range(1, num_epochs+1), train_iou_values, label='Train')
plt.plot(range(1, num_epochs+1), val_iou_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("IoU")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("Accuracy Graph")
plt.plot(range(1, num_epochs+1), train_acc_values, label='Train')
plt.plot(range(1, num_epochs+1), val_acc_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# load the best model
model.load_state_dict(torch.load('checkpoint.pt'))

# Testing
model.eval()
total_iou = 0
total_acc = 0
num_batches = len(test_dataloader)

for images, labels in test_dataloader:
    images = images.to(device)
    labels = labels.to(device)

    with torch.no_grad():
      output = model(images)['out']

    iou, acc = metrics_per_batch(output, labels, num_classes)
    total_iou += iou
    total_acc += acc

mean_iou = total_iou / num_batches
mean_acc = total_acc / num_batches

print(f"Test Mean IoU: {mean_iou}, Test Mean Accuracy: {mean_acc}")



#pre-trained model fcn_resnet101
import torch
from torchvision import models
from time import time
import matplotlib.pyplot as plt

def get_model(num_classes):
    model = models.segmentation.fcn_resnet101(pretrained=True, progress=True)
    model.classifier[4] = torch.nn.Conv2d(512, num_classes, kernel_size=(1, 1), stride=(1, 1))
    return model

def metrics_per_batch(output, target, num_classes):
    pred = output.argmax(dim=1).view(-1)
    target = target.view(-1)

    conf_matrix = torch.zeros(num_classes, num_classes)
    for t, p in zip(target, pred):
        conf_matrix[t.long(), p.long()] += 1

    iou_list = []
    for i in range(num_classes):
        true_class = conf_matrix[i, i]
        false_pos = conf_matrix[:, i].sum() - true_class
        false_neg = conf_matrix[i, :].sum() - true_class
        true_pos = true_class
        iou = true_pos / (true_pos + false_pos + false_neg + 1e-6)
        iou_list.append(iou)

    mean_iou = sum(iou_list) / num_classes

    total_correct = conf_matrix.trace()
    total_pixels = conf_matrix.sum()
    accuracy = total_correct / total_pixels

    return mean_iou, accuracy

num_classes = len(class_mapping)
model = get_model(num_classes)

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""
    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):
        
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        self.path = path
        self.trace_func = trace_func
    def __call__(self, val_loss, model):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0


    def save_checkpoint(self, val_loss, model):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

early_stopping = EarlyStopping(patience=7, path='checkpoint.pt')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

num_epochs = 10
train_loss_values = []
val_loss_values = []
train_iou_values = []
val_iou_values = []
train_acc_values = []
val_acc_values = []

start_time = time()
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    train_iou = 0.0
    train_acc = 0.0

    for images, labels in train_dataloader:
        images = images.to(device)
        labels = labels.long().to(device)

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs['out'], labels)

        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        iou, acc = metrics_per_batch(outputs['out'], labels, num_classes)
        train_iou += iou
        train_acc += acc

    train_loss /= len(train_dataloader)
    train_iou /= len(train_dataloader)
    train_acc /= len(train_dataloader)

    model.eval()
    val_loss = 0.0
    val_iou = 0.0
    val_acc = 0.0

    for images, labels in val_dataloader:
        images = images.to(device)
        labels = labels.long().to(device)

        with torch.no_grad():
            outputs = model(images)
            loss = criterion(outputs['out'], labels)

        val_loss += loss.item()
        iou, acc = metrics_per_batch(outputs['out'], labels, num_classes)
        val_iou += iou
        val_acc += acc

    val_loss /= len(val_dataloader)
    val_iou /= len(val_dataloader)
    val_acc /= len(val_dataloader)

    train_loss_values.append(train_loss)
    val_loss_values.append(val_loss)
    train_iou_values.append(train_iou)
    val_iou_values.append(val_iou)
    train_acc_values.append(train_acc)
    val_acc_values.append(val_acc)

    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Train IoU: {train_iou}, Val IoU: {val_iou}, Train Acc: {train_acc}, Val Acc: {val_acc}')

    scheduler.step()

    early_stopping(val_loss, model)
    if early_stopping.early_stop:
        print("Early stopping")
        break

end_time = time()

print(f"Training time: {end_time - start_time}")

model.load_state_dict(torch.load('checkpoint.pt'))

# Evaluation on the test dataset is similar to the evaluation on the validation dataset

plt.figure(figsize=(10, 5))
plt.title("Loss Graph")
plt.plot(range(1, num_epochs+1), train_loss_values, label='Train')
plt.plot(range(1, num_epochs+1), val_loss_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("IoU Graph")
plt.plot(range(1, num_epochs+1), train_iou_values, label='Train')
plt.plot(range(1, num_epochs+1), val_iou_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("IoU")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("Accuracy Graph")
plt.plot(range(1, num_epochs+1), train_acc_values, label='Train')
plt.plot(range(1, num_epochs+1), val_acc_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# load the best model
model.load_state_dict(torch.load('checkpoint.pt'))

# Testing
model.eval()
total_iou = 0
total_acc = 0
num_batches = len(val_dataloader)

for images, labels in val_dataloader:
    images = images.to(device)
    labels = labels.to(device)

    with torch.no_grad():
      output = model(images)['out']

    iou, acc = metrics_per_batch(output, labels, num_classes)
    total_iou += iou
    total_acc += acc

mean_iou = total_iou / num_batches
mean_acc = total_acc / num_batches

print(f"Test Mean IoU: {mean_iou}, Test Mean Accuracy: {mean_acc}")


#model 3
import torch
from torchvision import models
from time import time
import matplotlib.pyplot as plt
import segmentation_models_pytorch as smp


def get_model(num_classes):
    model = smp.PSPNet('resnet34',classes=num_classes,activation=None)
   
    return model

def metrics_per_batch(output, target, num_classes):
    pred = output.argmax(dim=1).view(-1)
    target = target.view(-1)

    conf_matrix = torch.zeros(num_classes, num_classes)
    for t, p in zip(target, pred):
        conf_matrix[t.long(), p.long()] += 1

    iou_list = []
    for i in range(num_classes):
        true_class = conf_matrix[i, i]
        false_pos = conf_matrix[:, i].sum() - true_class
        false_neg = conf_matrix[i, :].sum() - true_class
        true_pos = true_class
        iou = true_pos / (true_pos + false_pos + false_neg + 1e-6)
        iou_list.append(iou)

    mean_iou = sum(iou_list) / num_classes

    total_correct = conf_matrix.trace()
    total_pixels = conf_matrix.sum()
    accuracy = total_correct / total_pixels

    return mean_iou, accuracy

num_classes = len(class_mapping)
model = get_model(num_classes)

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""
    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):
       
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        self.path = path
        self.trace_func = trace_func
    def __call__(self, val_loss, model):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0


    def save_checkpoint(self, val_loss, model):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

early_stopping = EarlyStopping(patience=7, path='checkpoint.pt')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

num_epochs = 5
train_loss_values = []
val_loss_values = []
train_iou_values = []
val_iou_values = []
train_acc_values = []
val_acc_values = []

start_time = time()
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    train_iou = 0.0
    train_acc = 0.0

    for images, labels in train_dataloader:
        images = images.to(device)
        labels = labels.long().to(device)

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        iou, acc = metrics_per_batch(outputs, labels, num_classes)
        train_iou += iou
        train_acc += acc

    train_loss /= len(train_dataloader)
    train_iou /= len(train_dataloader)
    train_acc /= len(train_dataloader)

    model.eval()
    val_loss = 0.0
    val_iou = 0.0
    val_acc = 0.0

    for images, labels in val_dataloader:
        images = images.to(device)
        labels = labels.long().to(device)

        with torch.no_grad():
            outputs = model(images)
            loss = criterion(outputs, labels)

        val_loss += loss.item()
        iou, acc = metrics_per_batch(outputs, labels, num_classes)
        val_iou += iou
        val_acc += acc

    val_loss /= len(val_dataloader)
    val_iou /= len(val_dataloader)
    val_acc /= len(val_dataloader)

    train_loss_values.append(train_loss)
    val_loss_values.append(val_loss)
    train_iou_values.append(train_iou)
    val_iou_values.append(val_iou)
    train_acc_values.append(train_acc)
    val_acc_values.append(val_acc)

    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}, Train IoU: {train_iou}, Val IoU: {val_iou}, Train Acc: {train_acc}, Val Acc: {val_acc}')

    scheduler.step()

    early_stopping(val_loss, model)
    if early_stopping.early_stop:
        print("Early stopping")
        break

end_time = time()

print(f"Training time: {end_time - start_time}")

model.load_state_dict(torch.load('checkpoint.pt'))

# Evaluation on the test dataset is similar to the evaluation on the validation dataset

plt.figure(figsize=(10, 5))
plt.title("Loss Graph")
plt.plot(range(1, num_epochs+1), train_loss_values, label='Train')
plt.plot(range(1, num_epochs+1), val_loss_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("loss")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("IoU Graph")
plt.plot(range(1, num_epochs+1), train_iou_values, label='Train')
plt.plot(range(1, num_epochs+1), val_iou_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("IoU")
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("Accuracy Graph")
plt.plot(range(1, num_epochs+1), train_acc_values, label='Train')
plt.plot(range(1, num_epochs+1), val_acc_values, label='Validation')
plt.xlabel("epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# load the best model
model.load_state_dict(torch.load('checkpoint.pt'))

# Testing
model.eval()
total_iou = 0
total_acc = 0
num_batches = len(val_dataloader)

for images, labels in val_dataloader:
    images = images.to(device)
    labels = labels.to(device)

    with torch.no_grad():
      output = model(images)

    iou, acc = metrics_per_batch(output, labels, num_classes)
    total_iou += iou
    total_acc += acc

mean_iou = total_iou / num_batches
mean_acc = total_acc / num_batches

print(f"Test Mean IoU: {mean_iou}, Test Mean Accuracy: {mean_acc}")

